{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "456c9d1b-bda5-40cc-ba09-fff791aa3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9524316-df3a-4d23-b3a6-0e99f6732633",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "NIST_PATH = 'all_images/NIST/A_Z Handwritten Data.csv' # Defining the Dataset Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93160060-62df-48be-b1ae-a4c6f591632c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "# Intializing the tensorflow and GPU\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "if gpus >= 1:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "else: \n",
    "    print(f'GPU not found, Using CPU for tensorflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90a76d00-3f89-4851-bc33-992d02103ee5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def load_az_dataset(dataset_path):\n",
    "    # List for storing data\n",
    "    data = []\n",
    "    # List for storing labels\n",
    "    labels = []\n",
    "\n",
    "    for row in open(dataset_path): #Openfile and start reading each row\n",
    "        #Split the row at every comma\n",
    "        row = row.split(\",\")\n",
    "        #row[0] contains label\n",
    "        label = int(row[0])\n",
    "        #Other all collumns contains pixel values make a saperate array for that\n",
    "        img = np.array([int(x) for x in row[1:]], dtype=\"uint8\")\n",
    "        #Reshaping image to 28 x 28 pixels\n",
    "        img = img.reshape((28, 28))\n",
    "        #append image to data\n",
    "        data.append(img)\n",
    "        #append label to labels\n",
    "        labels.append(label)\n",
    "\n",
    "    #Converting data to numpy array of type float32\n",
    "    data = np.array(data, dtype='float32')\n",
    "    #Converting labels to type int\n",
    "    labels = np.array(labels, dtype=\"int\")\n",
    "\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf19f2b4-d944-4756-841d-204c776da9a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(images, labels) = load_az_dataset(NIST_PATH) # Using the fucntion to load the dataset\n",
    "\n",
    "images = [cv2.resize(image, (32, 32)) for image in images] # Resizing the images to 32 x 32\n",
    "images = np.array(images, dtype=\"float32\") # Converting to float 32 for tensorflow models\n",
    "\n",
    "# add a channel dimension to every image in the dataset and scale the\n",
    "# pixel intensities of the images from [0, 255] down to [0, 1]\n",
    "\n",
    "images = np.expand_dims(images, axis=-1) # Adding a Channel dimension as tensorflow models only accpet (H, W, C) or (B, H, W, C)\n",
    "images /= 255.0 # Normailzing the values from range [0 255] to [0 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "964679f4-d4db-45b1-b659-c294b9c5b354",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer # Importing the Label Binarizer to one hot encode the labels\n",
    "\n",
    "le = LabelBinarizer() # Calling the function\n",
    "labels = le.fit_transform(labels) # Fitting the labels and transforming the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00087b7f-f6f9-4a4b-9e94-bf83cc57cb46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # importing the train test split to split the dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2) # splitting the dataset\n",
    "\n",
    "del images, labels # deleting the old variabel to save RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac5f4458-4b35-4c71-a831-05a48076f477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((297960, 26), (74491, 26))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape # Getting a shape to verify/check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de23690d-286f-4a09-ab12-f16d44e6c04f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 32, 32, 1)        4         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        320       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 58)                14906     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 26)                1534      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,188,124\n",
      "Trainable params: 1,188,122\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Buidling the model\n",
    "\n",
    "# Importing the required layer classes\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "\n",
    "# Importing the Sequential\n",
    "from tensorflow.keras import Sequential\n",
    "\n",
    "# Calling the sequential\n",
    "model = Sequential()\n",
    "\n",
    "# Setting up a input to the model and defining the shape of input\n",
    "model.add(Input(shape=X_train.shape[1:]))\n",
    "\n",
    "# Adding the main layer\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(units=58, activation='relu'))\n",
    "model.add(Dense(units=26, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf549e7c-29bd-4214-9a57-671c043bed17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "37245/37245 [==============================] - 290s 8ms/step - loss: 0.1230 - accuracy: 0.9654 - val_loss: 0.0523 - val_accuracy: 0.9860\n",
      "Epoch 2/20\n",
      "37245/37245 [==============================] - 290s 8ms/step - loss: 0.0313 - accuracy: 0.9914 - val_loss: 0.0286 - val_accuracy: 0.9924\n",
      "Epoch 3/20\n",
      "37245/37245 [==============================] - 292s 8ms/step - loss: 0.0170 - accuracy: 0.9954 - val_loss: 0.0230 - val_accuracy: 0.9947\n",
      "Epoch 4/20\n",
      "37245/37245 [==============================] - 292s 8ms/step - loss: 0.0095 - accuracy: 0.9973 - val_loss: 0.0222 - val_accuracy: 0.9954\n",
      "Epoch 5/20\n",
      "37245/37245 [==============================] - 295s 8ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0193 - val_accuracy: 0.9965\n",
      "Epoch 6/20\n",
      "37245/37245 [==============================] - 295s 8ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0206 - val_accuracy: 0.9966\n",
      "Epoch 7/20\n",
      "37245/37245 [==============================] - 292s 8ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0258 - val_accuracy: 0.9967\n",
      "Epoch 8/20\n",
      "37245/37245 [==============================] - 294s 8ms/step - loss: 7.4992e-04 - accuracy: 0.9998 - val_loss: 0.0275 - val_accuracy: 0.9970\n",
      "Epoch 9/20\n",
      "37245/37245 [==============================] - 300s 8ms/step - loss: 3.7199e-04 - accuracy: 0.9999 - val_loss: 0.0330 - val_accuracy: 0.9971\n",
      "Epoch 10/20\n",
      "37245/37245 [==============================] - 290s 8ms/step - loss: 2.3798e-04 - accuracy: 0.9999 - val_loss: 0.0344 - val_accuracy: 0.9972\n",
      "Epoch 11/20\n",
      "37245/37245 [==============================] - 291s 8ms/step - loss: 1.1573e-04 - accuracy: 1.0000 - val_loss: 0.0409 - val_accuracy: 0.9973\n",
      "Epoch 12/20\n",
      "37245/37245 [==============================] - 288s 8ms/step - loss: 2.9251e-05 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9975\n",
      "Epoch 13/20\n",
      "37245/37245 [==============================] - 294s 8ms/step - loss: 7.2012e-05 - accuracy: 1.0000 - val_loss: 0.0530 - val_accuracy: 0.9974\n",
      "Epoch 14/20\n",
      "37245/37245 [==============================] - 300s 8ms/step - loss: 1.6363e-05 - accuracy: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9974\n",
      "Epoch 15/20\n",
      "37245/37245 [==============================] - 295s 8ms/step - loss: 1.2878e-06 - accuracy: 1.0000 - val_loss: 0.0625 - val_accuracy: 0.9975\n",
      "Epoch 16/20\n",
      "37245/37245 [==============================] - 299s 8ms/step - loss: 1.9275e-05 - accuracy: 1.0000 - val_loss: 0.0660 - val_accuracy: 0.9976\n",
      "Epoch 17/20\n",
      "37245/37245 [==============================] - 297s 8ms/step - loss: 2.0229e-05 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9976\n",
      "Epoch 18/20\n",
      "37245/37245 [==============================] - 299s 8ms/step - loss: 5.3522e-08 - accuracy: 1.0000 - val_loss: 0.0713 - val_accuracy: 0.9976\n",
      "Epoch 19/20\n",
      "37245/37245 [==============================] - 303s 8ms/step - loss: 6.5598e-06 - accuracy: 1.0000 - val_loss: 0.0723 - val_accuracy: 0.9976\n",
      "Epoch 20/20\n",
      "37245/37245 [==============================] - 323s 9ms/step - loss: 1.3523e-10 - accuracy: 1.0000 - val_loss: 0.0752 - val_accuracy: 0.9976\n"
     ]
    }
   ],
   "source": [
    "# Impoting the optimizer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "EPOCHS = 20 # Setting No. of Epochs\n",
    "BS = 8 # Setting Batch Size\n",
    "\n",
    "# Defining the optimizer and adding a decay to avoid overfit\n",
    "opt = Adam(learning_rate=1e-3, decay=1e-3 / EPOCHS)\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
    "\n",
    "# Fitting the model with training data and checking the performance with the testing data\n",
    "history = model.fit(X_train, y_train,\n",
    "              batch_size = BS,\n",
    "              validation_data=(X_test, y_test),\n",
    "              steps_per_epoch=len(X_train) // BS,\n",
    "              epochs=EPOCHS,\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04023b96-8485-48d2-9cc2-732c6b21356c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('./NIST_MODEL_1.h5') # Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c29d4ebc-67d2-413e-8cae-3924f658b447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pipeline to load new images for testing\n",
    "def pred_word_from_image(path, word=False, model_path='./NIST_MODEL_1.h5'):\n",
    "    #\n",
    "    import tensorflow as tf\n",
    "    import cv2\n",
    "    import matplotlib.pyplot as plt\n",
    "    #\n",
    "    label_letter_dict = {0:'a', 1:'b', 2:'c', 3:'d', 4:'e',\n",
    "                        5:'f', 6:'g', 7:'h', 8:'i', 9:'j',\n",
    "                        10:'k', 11:'l', 12:'m', 13:'n', 14:'o',\n",
    "                        15:'p', 16:'q', 17:'r', 18:'s', 19:'t',\n",
    "                        20:'u', 21:'v', 22:'w', 23:'x', 24:'y', 25:'z'}\n",
    "    #\n",
    "    if word:\n",
    "        pred_word = []\n",
    "        for i in path:\n",
    "            img = cv2.imread(i, cv2.IMREAD_COLOR)\n",
    "            img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.bitwise_not(img)\n",
    "            plt.imshow(img)\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            img = np.array(img, dtype=\"float32\")\n",
    "            img /= 255.0\n",
    "            model = tf.keras.models.load_model(model_path)\n",
    "            pred = model.predict(img)\n",
    "            #pred_word.append(label_letter_dict[le.inverse_transform(pred)])\n",
    "        return pred_word, pred\n",
    "    else:\n",
    "        img = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.bitwise_not(img)\n",
    "        plt.imshow(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = np.array(img, dtype=\"float32\")\n",
    "        img /= 255.0\n",
    "        model = tf.keras.models.load_model(model_path)\n",
    "        pred = np.argmax(model.predict(img), axis=1)\n",
    "        pred_letter = label_letter_dict[pred[0]]\n",
    "        return pred_letter, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a932026a-e1d7-4334-88c3-a3eccd2d5251",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('b', array([1], dtype=int64))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a_path = 'all_images/Cropped_Images/B_002.jpg'\n",
    "pred_word_from_image(a_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df20208-475e-4780-ab61-7052128a4d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
